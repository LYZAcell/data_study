{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LYZAcell/data_study/blob/main/BDA(%ED%8C%90%EB%8B%A4%EC%8A%A4)/%EA%B3%BC%EC%A0%9C/%EB%B3%B5%EC%8A%B5_%EC%9D%B4%EA%B0%80%EC%98%8141_0209_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "739906a1",
      "metadata": {
        "id": "739906a1",
        "outputId": "57b088d9-10fc-42e6-9a05-a6ae0b48094c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/jun/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /Users/jun/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /Users/jun/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /Users/jun/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/jun/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "#nltk 라이브러리\n",
        "nltk.download('punkt')\n",
        "nltk.download('webtext')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19c39425",
      "metadata": {
        "id": "19c39425",
        "outputId": "76fdef27-2a96-4467-f01f-b962356bdbbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Deep learning is the subset of machine learning methods based on artificial neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'Deep learning is the subset of machine learning methods based on artificial neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37d5d2fe",
      "metadata": {
        "id": "37d5d2fe"
      },
      "outputs": [],
      "source": [
        "## 어간 추출\n",
        "## 어형이 단어의 형태를 의미함, 어간은(stem) 어형 변화에서 변화하지 않는 부분을 말하는 것\n",
        "## cooking -> cook\n",
        "## 작다. 작으니, 작고, 작아서 등등\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20240cb7",
      "metadata": {
        "id": "20240cb7"
      },
      "outputs": [],
      "source": [
        "stemmer=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454e2a41",
      "metadata": {
        "id": "454e2a41",
        "outputId": "ae800a32-c9ca-4a4b-ee88-007fc56efa63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cook cook cooker\n"
          ]
        }
      ],
      "source": [
        "print(stemmer.stem('cooking'),stemmer.stem('cooked'),stemmer.stem('cooker'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db63b3a7",
      "metadata": {
        "id": "db63b3a7",
        "outputId": "78398123-b47e-4468-da1f-553c37c526ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cooking cooked cooker\n"
          ]
        }
      ],
      "source": [
        "##표제어 추출\n",
        "## 단어의 기본형\n",
        "lemma=WordNetLemmatizer()\n",
        "\n",
        "print(lemma.lemmatize('cooking'),lemma.lemmatize('cooked'),lemma.lemmatize('cooker'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ce2728",
      "metadata": {
        "id": "76ce2728",
        "outputId": "b57cde5f-32c0-4921-bd9c-888450698588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cook cooked cooker\n"
          ]
        }
      ],
      "source": [
        "print(lemma.lemmatize('cooking',pos='v'),lemma.lemmatize('cooked'),lemma.lemmatize('cooker'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fd87c2e",
      "metadata": {
        "id": "1fd87c2e"
      },
      "outputs": [],
      "source": [
        "##품사태깅\n",
        "##토큰화, 정규화를 통해서 ->결과가 나온 것을 형태소로 본다.\n",
        "##형태소는 의미를 가진 가장 작은 말의 단위 -> 의미를 더 나누게 되면 본래의 뜻을 잃을 수 있다.\n",
        "##책가방 책+가방 ->형태소로 볼 수 있음\n",
        "##가방 가+방 ->형태소로 볼 수 없다.\n",
        "## '명사, 대명사, 수사, 조사, 형용사. 관형사, 부사 등등' 공통된 성질을 지닌 낱말들끼리 모아 놓은 것들\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens =word_tokenize('Deep learning is the subset of machine learning methods based on artificial neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87e93a0a",
      "metadata": {
        "id": "87e93a0a",
        "outputId": "d8025f27-924d-4739-f785-08ae08e8bf27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Deep', 'JJ'), ('learning', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('subset', 'NN'), ('of', 'IN'), ('machine', 'NN'), ('learning', 'VBG'), ('methods', 'NNS'), ('based', 'VBN'), ('on', 'IN'), ('artificial', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('with', 'IN'), ('representation', 'NN'), ('learning', 'NN'), ('.', '.'), ('The', 'DT'), ('adjective', 'JJ'), ('``', '``'), ('deep', 'JJ'), (\"''\", \"''\"), ('refers', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('multiple', 'JJ'), ('layers', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('network', 'NN'), ('.', '.'), ('Methods', 'NNS'), ('used', 'VBD'), ('can', 'MD'), ('be', 'VB'), ('either', 'RB'), ('supervised', 'VBN'), (',', ','), ('semi-supervised', 'JJ'), ('or', 'CC'), ('unsupervised', 'JJ')]\n"
          ]
        }
      ],
      "source": [
        "print(nltk.pos_tag(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1c4ad4a",
      "metadata": {
        "id": "f1c4ad4a",
        "outputId": "e3db8179-61a0-4437-ae14-9ff094a09139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n"
          ]
        }
      ],
      "source": [
        "nltk.help.upenn_tagset('CC')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9346e967",
      "metadata": {
        "id": "9346e967"
      },
      "source": [
        "### 한글을 가지고 형태소를 분석하고 품사를 태깅해 보자!\n",
        "\n",
        "- KoNLPy -한국어 형태소 분석 및 품사 태깅 라이브러리\n",
        "- Kkma, Komoran, Twitter, Mecab, Hannaum, Okt\n",
        "\n",
        "- https://konlpy.org/ko/latest/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62797276",
      "metadata": {
        "id": "62797276"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "k=Okt()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a276dc4b",
      "metadata": {
        "id": "a276dc4b"
      },
      "source": [
        "- morphs(phrase)-> 형태소 단위로 분리 -> 형태소의 리스트\n",
        "- nouns(phrase) -> 형태소 단위로 분리해서 명사만 반환\n",
        "- pos(pharse) ->형태소 분리하고 품사 부착해서 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6edfeca0",
      "metadata": {
        "id": "6edfeca0"
      },
      "outputs": [],
      "source": [
        "data=\"\"\"[BDA 10기 모집 오픈채팅방 운영 기간 연장 안내]\n",
        "\n",
        "안녕하세요, BDA 운영진입니다.\n",
        "\n",
        "BDA 10기 모집을 위한 오픈 카카오톡 채팅방 운영 기간이 연장되었습니다!\n",
        "기존 2월 7일(금) → 2월 18일(화)까지로 연장되었으니, 아직 참여하지 못한 분들은 기회를 놓치지 마세요.\n",
        "\n",
        "이번 모집 연장은 2월부터 시작될 다양한 행사 및 활동에 더 많은 학회원들이 참여할 수 있도록 하기 위한 결정입니다. 관심 있는 분들은 꼭 참여해 주세요!\n",
        "\n",
        "🔹 [BDA 10기 모집 일정 재안내]\n",
        "📌 1/13 ~ 2/18 : 모집 오픈채팅방 링크 공지\n",
        "📌 2/5 ~ 2/11 : 분반 수요 조사\n",
        "📌 2/12 ~ 2/18 : 실제 모집 진행 (12일부터 구글 폼 공유 예정)\n",
        "📌 3/5 ~ 3/8 : 첫 수업 진행\n",
        "📌 3/5 ~ 3/12 : 환불 및 분반 변경 기간\n",
        "\n",
        "📢 참여를 원하시는 분들은 오픈채팅방을 통해 최신 정보를 확인해 주세요!\n",
        "많은 관심과 참여 부탁드립니다. 😊\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0108d55",
      "metadata": {
        "id": "a0108d55",
        "outputId": "cdd86ce2-2d4d-48c7-b5cf-cbd43879acaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BDA 10기 모집 오픈채팅방 운영 기간 연장 안내]\n",
            "\n",
            "안녕하세요, BDA 운영진입니다.\n",
            "\n",
            "BDA 10기 모집을 위한 오픈 카카오톡 채팅방 운영 기간이 연장되었습니다!\n",
            "기존 2월 7일(금) → 2월 18일(화)까지로 연장되었으니, 아직 참여하지 못한 분들은 기회를 놓치지 마세요.\n",
            "\n",
            "이번 모집 연장은 2월부터 시작될 다양한 행사 및 활동에 더 많은 학회원들이 참여할 수 있도록 하기 위한 결정입니다. 관심 있는 분들은 꼭 참여해 주세요!\n",
            "\n",
            "🔹 [BDA 10기 모집 일정 재안내]\n",
            "📌 1/13 ~ 2/18 : 모집 오픈채팅방 링크 공지\n",
            "📌 2/5 ~ 2/11 : 분반 수요 조사\n",
            "📌 2/12 ~ 2/18 : 실제 모집 진행 (12일부터 구글 폼 공유 예정)\n",
            "📌 3/5 ~ 3/8 : 첫 수업 진행\n",
            "📌 3/5 ~ 3/12 : 환불 및 분반 변경 기간\n",
            "\n",
            "📢 참여를 원하시는 분들은 오픈채팅방을 통해 최신 정보를 확인해 주세요!\n",
            "많은 관심과 참여 부탁드립니다. 😊\n",
            "['기', '모집', '오픈', '채팅', '방', '운영', '기간', '연장', '안내', '운영', '진입', '니', '기', '모집', '위', '오픈', '카카오', '톡', '채팅', '방', '운영', '기간', '연장', '기존', '금', '화', '연장', '참여', '못', '분', '기회', '이번', '모집', '연장', '시작', '행사', '및', '활동', '더', '학회', '참여', '수', '위', '결정', '관심', '분', '꼭', '참여', '기', '모집', '일정', '모집', '오픈', '채팅', '방', '링크', '공지', '분반', '수요', '조사', '실제', '모집', '진행', '구글', '폼', '공유', '예정', '첫', '수업', '진행', '환불', '및', '분반', '변경', '기간', '참여', '분', '오픈', '채팅', '방', '통해', '최신', '정보', '확인', '관심', '참여']\n"
          ]
        }
      ],
      "source": [
        "print(data)\n",
        "print(k.nouns(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d032ed9f",
      "metadata": {
        "id": "d032ed9f",
        "outputId": "d9ec89c2-4ddd-4f39-f28e-55e556228920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('[', 'Punctuation'), ('BDA', 'Alpha'), ('10', 'Number'), ('기', 'Noun'), ('모집', 'Noun'), ('오픈', 'Noun'), ('채팅', 'Noun'), ('방', 'Noun'), ('운영', 'Noun'), ('기간', 'Noun'), ('연장', 'Noun'), ('안내', 'Noun'), (']', 'Punctuation'), ('\\n\\n', 'Foreign'), ('안녕하세요', 'Adjective'), (',', 'Punctuation'), ('BDA', 'Alpha'), ('운영', 'Noun'), ('진입', 'Noun'), ('니', 'Noun'), ('다', 'Josa'), ('.', 'Punctuation'), ('\\n\\n', 'Foreign'), ('BDA', 'Alpha'), ('10', 'Number'), ('기', 'Noun'), ('모집', 'Noun'), ('을', 'Josa'), ('위', 'Noun'), ('한', 'Josa'), ('오픈', 'Noun'), ('카카오', 'Noun'), ('톡', 'Noun'), ('채팅', 'Noun'), ('방', 'Noun'), ('운영', 'Noun'), ('기간', 'Noun'), ('이', 'Josa'), ('연장', 'Noun'), ('되었습니다', 'Verb'), ('!', 'Punctuation'), ('\\n', 'Foreign'), ('기존', 'Noun'), ('2월', 'Number'), ('7일', 'Number'), ('(', 'Punctuation'), ('금', 'Noun'), (')', 'Punctuation'), ('→', 'Foreign'), ('2월', 'Number'), ('18일', 'Number'), ('(', 'Punctuation'), ('화', 'Noun'), (')', 'Punctuation'), ('까지로', 'Josa'), ('연장', 'Noun'), ('되었으니', 'Verb'), (',', 'Punctuation'), ('아직', 'Adverb'), ('참여', 'Noun'), ('하지', 'Verb'), ('못', 'Noun'), ('한', 'Josa'), ('분', 'Noun'), ('들', 'Suffix'), ('은', 'Josa'), ('기회', 'Noun'), ('를', 'Josa'), ('놓치지', 'Verb'), ('마세요', 'Verb'), ('.', 'Punctuation'), ('\\n\\n', 'Foreign'), ('이번', 'Noun'), ('모집', 'Noun'), ('연장', 'Noun'), ('은', 'Josa'), ('2월', 'Number'), ('부터', 'Foreign'), ('시작', 'Noun'), ('될', 'Verb'), ('다양한', 'Adjective'), ('행사', 'Noun'), ('및', 'Noun'), ('활동', 'Noun'), ('에', 'Josa'), ('더', 'Noun'), ('많은', 'Adjective'), ('학회', 'Noun'), ('원', 'Suffix'), ('들이', 'Verb'), ('참여', 'Noun'), ('할', 'Verb'), ('수', 'Noun'), ('있도록', 'Adjective'), ('하기', 'Verb'), ('위', 'Noun'), ('한', 'Josa'), ('결정', 'Noun'), ('입니다', 'Adjective'), ('.', 'Punctuation'), ('관심', 'Noun'), ('있는', 'Adjective'), ('분', 'Noun'), ('들', 'Suffix'), ('은', 'Josa'), ('꼭', 'Noun'), ('참여', 'Noun'), ('해', 'Verb'), ('주세요', 'Verb'), ('!', 'Punctuation'), ('\\n\\n', 'Foreign'), ('🔹', 'Foreign'), ('[', 'Punctuation'), ('BDA', 'Alpha'), ('10', 'Number'), ('기', 'Noun'), ('모집', 'Noun'), ('일정', 'Noun'), ('재안내', 'Verb'), (']', 'Punctuation'), ('\\n', 'Foreign'), ('📌', 'Foreign'), ('1/13', 'Number'), ('~', 'Punctuation'), ('2/18', 'Number'), (':', 'Punctuation'), ('모집', 'Noun'), ('오픈', 'Noun'), ('채팅', 'Noun'), ('방', 'Noun'), ('링크', 'Noun'), ('공지', 'Noun'), ('\\n', 'Foreign'), ('📌', 'Foreign'), ('2/5', 'Number'), ('~', 'Punctuation'), ('2/11', 'Number'), (':', 'Punctuation'), ('분반', 'Noun'), ('수요', 'Noun'), ('조사', 'Noun'), ('\\n', 'Foreign'), ('📌', 'Foreign'), ('2/12', 'Number'), ('~', 'Punctuation'), ('2/18', 'Number'), (':', 'Punctuation'), ('실제', 'Noun'), ('모집', 'Noun'), ('진행', 'Noun'), ('(', 'Punctuation'), ('12일', 'Number'), ('부터', 'Foreign'), ('구글', 'Noun'), ('폼', 'Noun'), ('공유', 'Noun'), ('예정', 'Noun'), (')', 'Punctuation'), ('\\n', 'Foreign'), ('📌', 'Foreign'), ('3/5', 'Number'), ('~', 'Punctuation'), ('3/8', 'Number'), (':', 'Punctuation'), ('첫', 'Noun'), ('수업', 'Noun'), ('진행', 'Noun'), ('\\n', 'Foreign'), ('📌', 'Foreign'), ('3/5', 'Number'), ('~', 'Punctuation'), ('3/12', 'Number'), (':', 'Punctuation'), ('환불', 'Noun'), ('및', 'Noun'), ('분반', 'Noun'), ('변경', 'Noun'), ('기간', 'Noun'), ('\\n\\n', 'Foreign'), ('📢', 'Foreign'), ('참여', 'Noun'), ('를', 'Josa'), ('원하시는', 'Adjective'), ('분', 'Noun'), ('들', 'Suffix'), ('은', 'Josa'), ('오픈', 'Noun'), ('채팅', 'Noun'), ('방', 'Noun'), ('을', 'Josa'), ('통해', 'Noun'), ('최신', 'Noun'), ('정보', 'Noun'), ('를', 'Josa'), ('확인', 'Noun'), ('해', 'Verb'), ('주세요', 'Verb'), ('!', 'Punctuation'), ('\\n', 'Foreign'), ('많은', 'Adjective'), ('관심', 'Noun'), ('과', 'Josa'), ('참여', 'Noun'), ('부탁드립니다', 'Adjective'), ('.', 'Punctuation'), ('😊', 'Foreign')]\n"
          ]
        }
      ],
      "source": [
        "print(k.pos(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a538d4",
      "metadata": {
        "id": "36a538d4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('movie_rv.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4c7498",
      "metadata": {
        "id": "cc4c7498"
      },
      "outputs": [],
      "source": [
        "df_sp=df.iloc[:10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c9e1f96",
      "metadata": {
        "id": "4c9e1f96"
      },
      "source": [
        "## 문서를 임베딩하는 방법\n",
        "- Bow( Bag of Words)\n",
        "    - 카운트기반의 문서 표현\n",
        "- CountVectorizer 패키지를 가지고 간단하게 표현할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4839f6b",
      "metadata": {
        "id": "b4839f6b"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd5f18f4",
      "metadata": {
        "id": "fd5f18f4"
      },
      "outputs": [],
      "source": [
        "#예시 샘플 데이터\n",
        "\n",
        "corpus =[\n",
        "    'This is the first corpus',\n",
        "    'This corpus is the second corpus',\n",
        "    'And this corpus is the third one',\n",
        "    'Is this the sencond corpus?'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7c3964b",
      "metadata": {
        "id": "c7c3964b",
        "outputId": "2dd09176-207d-4b70-8faf-0091209c52dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This is the first corpus',\n",
              " 'This corpus is the second corpus',\n",
              " 'And this corpus is the third one',\n",
              " 'Is this the sencond corpus?']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc84efdb",
      "metadata": {
        "id": "fc84efdb"
      },
      "outputs": [],
      "source": [
        "c=CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6506703",
      "metadata": {
        "id": "f6506703"
      },
      "outputs": [],
      "source": [
        "#벡터화해서 만들어 준다.\n",
        "X=c.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7567f0d8",
      "metadata": {
        "id": "7567f0d8",
        "outputId": "b8fc32d0-af84-428b-8e8d-1cd1019733b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corpus에서 사용한 피처는 무엇인지 보고 싶다! ['and' 'corpus' 'first' 'is' 'one' 'second' 'sencond' 'the' 'third' 'this']\n"
          ]
        }
      ],
      "source": [
        "print('corpus에서 사용한 피처는 무엇인지 보고 싶다!', c.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5009263a",
      "metadata": {
        "id": "5009263a",
        "outputId": "90953858-3ad7-47e2-bf8e-3d92f6a42395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "어떤 식으로 메트릭스가 만들어졌나?   (0, 9)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 1)\t1\n",
            "  (1, 9)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 7)\t1\n",
            "  (1, 1)\t2\n",
            "  (1, 5)\t1\n",
            "  (2, 9)\t1\n",
            "  (2, 3)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 8)\t1\n",
            "  (2, 4)\t1\n",
            "  (3, 9)\t1\n",
            "  (3, 3)\t1\n",
            "  (3, 7)\t1\n",
            "  (3, 1)\t1\n",
            "  (3, 6)\t1\n"
          ]
        }
      ],
      "source": [
        "print('어떤 식으로 메트릭스가 만들어졌나?', X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b1cbc1d",
      "metadata": {
        "id": "4b1cbc1d",
        "outputId": "3313f1bd-fa40-494e-fb8f-ca3826eabeea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 0, 0, 1, 0, 1],\n",
              "       [0, 2, 0, 1, 0, 1, 0, 1, 0, 1],\n",
              "       [1, 1, 0, 1, 1, 0, 0, 1, 1, 1],\n",
              "       [0, 1, 0, 1, 0, 0, 1, 1, 0, 1]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7afceeb8",
      "metadata": {
        "id": "7afceeb8",
        "outputId": "444da8d6-cb12-4250-aa73-418452b50490"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This is the first corpus',\n",
              " 'This corpus is the second corpus',\n",
              " 'And this corpus is the third one',\n",
              " 'Is this the sencond corpus?']"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99262af",
      "metadata": {
        "id": "b99262af"
      },
      "outputs": [],
      "source": [
        "## 한국어 진행\n",
        "corpus_ko =[\n",
        "    '오늘 날씨 너무 추워요.',\n",
        "    '내일 날씨 너무 추울까요?',\n",
        "    '내일은 덜 추우면 좋겠다.',\n",
        "    '모두 내일은 방학인가요?',\n",
        "    '방학에는 공부를 열심히 해야죠!',\n",
        "    'BDA도 방학에 공부를 더 많이 하죠',\n",
        "    'BDA 10기를 모집한다고요.',\n",
        "    '10기까지 왔구나',\n",
        "    '10기는 다양한 사람들이 더 모일 것 같아요!'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f6f050",
      "metadata": {
        "id": "e3f6f050",
        "outputId": "040848df-6b56-45d9-81f4-1a15c55ab9bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['오늘 날씨 너무 추워요.',\n",
              " '내일 날씨 너무 추울까요?',\n",
              " '내일은 덜 추우면 좋겠다.',\n",
              " '모두 내일은 방학인가요?',\n",
              " '방학에는 공부를 열심히 해야죠!',\n",
              " 'BDA도 방학에 공부를 더 많이 하죠',\n",
              " 'BDA 10기를 모집한다고요.',\n",
              " '10기까지 왔구나',\n",
              " '10기는 다양한 사람들이 더 모일 것 같아요!']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_ko"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b961d392",
      "metadata": {
        "id": "b961d392"
      },
      "outputs": [],
      "source": [
        "c=CountVectorizer()\n",
        "#벡터화해서 만들어 준다.\n",
        "X=c.fit_transform(corpus_ko)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efa1d113",
      "metadata": {
        "id": "efa1d113",
        "outputId": "36d773fa-9084-4947-c042-b600cb537826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corpus에서 사용한 피처는 무엇인지 보고 싶다! ['10기까지' '10기는' '10기를' 'bda' 'bda도' '같아요' '공부를' '날씨' '내일' '내일은' '너무' '다양한'\n",
            " '많이' '모두' '모일' '모집한다고요' '방학에' '방학에는' '방학인가요' '사람들이' '열심히' '오늘' '왔구나'\n",
            " '좋겠다' '추우면' '추울까요' '추워요' '하죠' '해야죠']\n",
            "어떤 식으로 메트릭스가 만들어졌나?   (0, 21)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 10)\t1\n",
            "  (0, 26)\t1\n",
            "  (1, 7)\t1\n",
            "  (1, 10)\t1\n",
            "  (1, 8)\t1\n",
            "  (1, 25)\t1\n",
            "  (2, 9)\t1\n",
            "  (2, 24)\t1\n",
            "  (2, 23)\t1\n",
            "  (3, 9)\t1\n",
            "  (3, 13)\t1\n",
            "  (3, 18)\t1\n",
            "  (4, 17)\t1\n",
            "  (4, 6)\t1\n",
            "  (4, 20)\t1\n",
            "  (4, 28)\t1\n",
            "  (5, 6)\t1\n",
            "  (5, 4)\t1\n",
            "  (5, 16)\t1\n",
            "  (5, 12)\t1\n",
            "  (5, 27)\t1\n",
            "  (6, 3)\t1\n",
            "  (6, 2)\t1\n",
            "  (6, 15)\t1\n",
            "  (7, 0)\t1\n",
            "  (7, 22)\t1\n",
            "  (8, 1)\t1\n",
            "  (8, 11)\t1\n",
            "  (8, 19)\t1\n",
            "  (8, 14)\t1\n",
            "  (8, 5)\t1\n"
          ]
        }
      ],
      "source": [
        "print('corpus에서 사용한 피처는 무엇인지 보고 싶다!', c.get_feature_names_out())\n",
        "print('어떤 식으로 메트릭스가 만들어졌나?', X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad20ec8",
      "metadata": {
        "id": "aad20ec8",
        "outputId": "1d0fb3c2-87d4-4732-9b33-d3a6719c5662"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65ffc77a",
      "metadata": {
        "id": "65ffc77a",
        "outputId": "91171542-1fe1-4a60-9c81-dce3b4151719"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['오늘 날씨 너무 추워요.',\n",
              " '내일 날씨 너무 추울까요?',\n",
              " '내일은 덜 추우면 좋겠다.',\n",
              " '모두 내일은 방학인가요?',\n",
              " '방학에는 공부를 열심히 해야죠!',\n",
              " 'BDA도 방학에 공부를 더 많이 하죠',\n",
              " 'BDA 10기를 모집한다고요.',\n",
              " '10기까지 왔구나',\n",
              " '10기는 다양한 사람들이 더 모일 것 같아요!']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_ko"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22ec7f2c",
      "metadata": {
        "id": "22ec7f2c"
      },
      "source": [
        "## TF-IDF\n",
        "- (Term Frequency - Inverse Document Frequency)\n",
        "- 일종의 가중치를 사용하는 것\n",
        "- 카운트 벡터에서 빈도가 높을수록 중요한 단어로 생각하는데 -> 이게 정말 중요한 단어입니까?\n",
        "- 단어가 더 많은 문서에서 나타날수록 그 단어는 별로 중요하지 않게 된다. 이러한 의미를 카운트 벡터에 반영한 것이 TF-IDF\n",
        "- 단어빈도- 역문서빈도\n",
        "- 카운트 대신 단어의 빈도에 그 단어가 출현한 문서 수의 역수를 곱했다.\n",
        "- 단어가 나타난 문서의 수가 클수록 이 값은 작아진다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ffe518a",
      "metadata": {
        "id": "0ffe518a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "936e4f92",
      "metadata": {
        "id": "936e4f92",
        "outputId": "b14c8f63-a6af-469d-ef63-ddf19d75a364"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['오늘 날씨 너무 추워요.',\n",
              " '내일 날씨 너무 추울까요?',\n",
              " '내일은 덜 추우면 좋겠다.',\n",
              " '모두 내일은 방학인가요?',\n",
              " '방학에는 공부를 열심히 해야죠!',\n",
              " 'BDA도 방학에 공부를 더 많이 하죠',\n",
              " 'BDA 10기를 모집한다고요.',\n",
              " '10기까지 왔구나',\n",
              " '10기는 다양한 사람들이 더 모일 것 같아요!']"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_ko"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445d93fb",
      "metadata": {
        "id": "445d93fb"
      },
      "outputs": [],
      "source": [
        "tfidf=TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec553d72",
      "metadata": {
        "id": "ec553d72"
      },
      "outputs": [],
      "source": [
        "tfidf_X=tfidf.fit_transform(corpus_ko)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20bc260a",
      "metadata": {
        "id": "20bc260a",
        "outputId": "646c01ed-8a59-4d03-a257-6ff5e443f698"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<9x29 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 33 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ec555b",
      "metadata": {
        "id": "53ec555b",
        "outputId": "33c83b60-c9c7-4381-8b3c-6c03d661ce9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corpus에서 사용한 피처는 무엇인지 보고 싶다! ['10기까지' '10기는' '10기를' 'bda' 'bda도' '같아요' '공부를' '날씨' '내일' '내일은' '너무' '다양한'\n",
            " '많이' '모두' '모일' '모집한다고요' '방학에' '방학에는' '방학인가요' '사람들이' '열심히' '오늘' '왔구나'\n",
            " '좋겠다' '추우면' '추울까요' '추워요' '하죠' '해야죠']\n",
            "어떤 식으로 메트릭스가 만들어졌나?   (0, 26)\t0.5402050699288926\n",
            "  (0, 10)\t0.4562658023818137\n",
            "  (0, 7)\t0.4562658023818137\n",
            "  (0, 21)\t0.5402050699288926\n",
            "  (1, 25)\t0.5402050699288926\n",
            "  (1, 8)\t0.5402050699288926\n",
            "  (1, 10)\t0.4562658023818137\n",
            "  (1, 7)\t0.4562658023818137\n",
            "  (2, 23)\t0.6070787148636269\n",
            "  (2, 24)\t0.6070787148636269\n",
            "  (2, 9)\t0.5127483475537044\n",
            "  (3, 18)\t0.6070787148636269\n",
            "  (3, 13)\t0.6070787148636269\n",
            "  (3, 9)\t0.5127483475537044\n",
            "  (4, 28)\t0.5189380717981641\n",
            "  (4, 20)\t0.5189380717981641\n",
            "  (4, 6)\t0.438303357179945\n",
            "  (4, 17)\t0.5189380717981641\n",
            "  (5, 27)\t0.4606106279676078\n",
            "  (5, 12)\t0.4606106279676078\n",
            "  (5, 16)\t0.4606106279676078\n",
            "  (5, 4)\t0.4606106279676078\n",
            "  (5, 6)\t0.3890390695202013\n",
            "  (6, 15)\t0.5773502691896258\n",
            "  (6, 2)\t0.5773502691896258\n",
            "  (6, 3)\t0.5773502691896258\n",
            "  (7, 22)\t0.7071067811865476\n",
            "  (7, 0)\t0.7071067811865476\n",
            "  (8, 5)\t0.4472135954999579\n",
            "  (8, 14)\t0.4472135954999579\n",
            "  (8, 19)\t0.4472135954999579\n",
            "  (8, 11)\t0.4472135954999579\n",
            "  (8, 1)\t0.4472135954999579\n"
          ]
        }
      ],
      "source": [
        "print('corpus에서 사용한 피처는 무엇인지 보고 싶다!', tfidf.get_feature_names_out())\n",
        "print('어떤 식으로 메트릭스가 만들어졌나?', tfidf_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7b0bcaa",
      "metadata": {
        "scrolled": true,
        "id": "f7b0bcaa",
        "outputId": "0c14d602-67ea-42a2-ff30-171d5de4b62d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.4562658 , 0.        , 0.        ,\n",
              "        0.4562658 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.54020507, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.54020507, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.4562658 , 0.54020507, 0.        ,\n",
              "        0.4562658 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.54020507, 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.51274835,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.60707871, 0.60707871,\n",
              "        0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.51274835,\n",
              "        0.        , 0.        , 0.        , 0.60707871, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.60707871, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.43830336, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.51893807, 0.        , 0.        ,\n",
              "        0.51893807, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.51893807],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.46061063,\n",
              "        0.        , 0.38903907, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46061063, 0.        , 0.        ,\n",
              "        0.        , 0.46061063, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46061063, 0.        ],\n",
              "       [0.        , 0.        , 0.57735027, 0.57735027, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.70710678, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.70710678, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.4472136 , 0.        , 0.        , 0.        ,\n",
              "        0.4472136 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.4472136 , 0.        , 0.        , 0.4472136 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.4472136 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_X.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ccc20ff",
      "metadata": {
        "id": "6ccc20ff"
      },
      "outputs": [],
      "source": [
        "stop_words = ['bda도']\n",
        "##stop_words, min_df 최소 1회 이상 최소의 횟수를 나타나는 단어만 포함, ngram 주변 단어를 같이 묶어서 벡터 학습\n",
        "tfidf_tun=TfidfVectorizer(stop_words = stop_words, min_df =2, ngram_range=(1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f33036ff",
      "metadata": {
        "id": "f33036ff"
      },
      "outputs": [],
      "source": [
        "X_tun=tfidf_tun.fit_transform(corpus_ko)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceeb96bd",
      "metadata": {
        "id": "ceeb96bd",
        "outputId": "af9e048d-863d-47af-c0b5-167cbaecc18b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<9x5 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 10 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_tun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00013ec3",
      "metadata": {
        "id": "00013ec3",
        "outputId": "232c638f-a1ec-4638-f7fb-49c43fbe125b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corpus에서 사용한 피처는 무엇인지 보고 싶다! ['공부를' '날씨' '날씨 너무' '내일은' '너무']\n",
            "어떤 식으로 메트릭스가 만들어졌나?   (0, 2)\t0.5773502691896257\n",
            "  (0, 4)\t0.5773502691896257\n",
            "  (0, 1)\t0.5773502691896257\n",
            "  (1, 2)\t0.5773502691896257\n",
            "  (1, 4)\t0.5773502691896257\n",
            "  (1, 1)\t0.5773502691896257\n",
            "  (2, 3)\t1.0\n",
            "  (3, 3)\t1.0\n",
            "  (4, 0)\t1.0\n",
            "  (5, 0)\t1.0\n"
          ]
        }
      ],
      "source": [
        "print('corpus에서 사용한 피처는 무엇인지 보고 싶다!', tfidf_tun.get_feature_names_out())\n",
        "print('어떤 식으로 메트릭스가 만들어졌나?', X_tun)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02bf107c",
      "metadata": {
        "id": "02bf107c",
        "outputId": "7e84fb79-42b9-43a0-a0da-77c2cdd4079c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['오늘 날씨 너무 추워요.',\n",
              " '내일 날씨 너무 추울까요?',\n",
              " '내일은 덜 추우면 좋겠다.',\n",
              " '모두 내일은 방학인가요?',\n",
              " '방학에는 공부를 열심히 해야죠!',\n",
              " 'BDA도 방학에 공부를 더 많이 하죠',\n",
              " 'BDA 10기를 모집한다고요.',\n",
              " '10기까지 왔구나',\n",
              " '10기는 다양한 사람들이 더 모일 것 같아요!']"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_ko"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b02d52ab",
      "metadata": {
        "id": "b02d52ab",
        "outputId": "38b89d88-95e1-40f6-93de-7dd830b63752"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
              "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
              "       [0.        , 0.        , 0.        , 1.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 1.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_tun.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4acd696",
      "metadata": {
        "id": "b4acd696"
      },
      "source": [
        "## 필수과제1\n",
        "- movie 데이터를 가지고 countvectorizer 벡터화 진행\n",
        "- movie 데이터를 가지고 tf-idf 벡터화 진행\n",
        "\n",
        "- 단 그대로 벡터를 만드는 게 아니라 전처리 진행 후 -> 차원 확인, 유의미한 형태소로 묶였는지 체크하고, 필요 없는 것들은 불용어처리로 제거하여 최대한 벡터 차원을 줄이는 것을 목표로 진행!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb46ea8",
      "metadata": {
        "id": "bbb46ea8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}